[
  {
    "objectID": "education.html",
    "href": "education.html",
    "title": "Education & Certifications",
    "section": "",
    "text": "🎓 Education\n\n\n\n\nMaster of Data Science (MDS)\n\n\nUniversity of British Columbia (UBC) | 2024–2025\n\n\nFocus areas include: Machine Learning, Deep Learning, Data Structures, Docker, CI/CD Pipelines, AWS Cloud Services, Big Data, Statistical Modeling, Causal Inference, and Bayesian Statistics.\n\n\n\n\n\n\n\n\n\nBachelor of Technology (B.Tech)\n\n\nShiv Nadar University | 2017–2021\n\n\nMajor: Electrical and Electronics Engineering\n\n\n\n\n\n\n📜 Certifications\n\n\n\n\nData Science Portfolio\n\n\nDataCamp | Completed 2024\n\n\nMy DataCamp portfolio showcases all the certifications I’ve completed, including courses on machine learning, data visualisation, statistical modeling, SQL analytics, and more."
  },
  {
    "objectID": "readme.html",
    "href": "readme.html",
    "title": "Dhruv Garg — Portfolio Website",
    "section": "",
    "text": "This is the source for my personal portfolio website, built using Quarto, HTML, and CSS.\nIt showcases my: - Projects - Education - Experience - Resume - Contact links\n\n\n\n├── index.qmd           # Homepage\n├── about.qmd           # About Me page\n├── projects.qmd        # Listing page for all projects \n├── resume.qmd          # Resume page \n├── education.qmd       # Education and certifications \n├── posts/              # Folder containing individual project pages\n│    ├── project1.qmd\n│    ├── project2.qmd\n│    └── ...\n├── images/             # Images (logos, project screenshots, gifs)\n├── styles.css          # Custom CSS for layout and design\n├── _quarto.yml         # Quarto site configuration\n└── README.md           # This file\n\n\n\n\n\n\n\nThe homepage contains cards for:\n\nProjects\nEducation\nExperience\n\nImportant: The “View Education” button links to education.qmd.\n\n\nTo add/change cards on the homepage, edit the &lt;div class=\"portfolio-card\"&gt; blocks inside index.qmd.\n\n\n\n\n\n\nprojects.qmd lists projects automatically if you use the listing: feature.\nEach project has a file inside the posts/ folder.\nExample project file: posts/retailpulse.qmd\n\n\nTo add a new project, create a new .qmd inside posts/ and Quarto will pick it up.\n\n\n\n\n\n\neducation.qmd uses a stacked layout — degrees first, certificates after.\nTo add a new degree or certificate:\n\nCopy an &lt;div class=\"education-item\"&gt; block.\nUpdate the title, organization, year, and description.\n(Optional) Add/update logos in images/.\n\n\n\n\n\n\n\nLinked to experience.qmd.\n\n\n\n\n\n\nMain styling such as:\n\nCard layout\nSection headings\nButton hover effects\nFonts and responsiveness\n\nEdit styles.css to customize the look of cards, sections, or entire site theme.\n\n\n\n\n\n\nControls the navbar links, site title, theme, and external assets.\nIf you add a new major page like education.qmd or experience.qmd, consider adding it to _quarto.yml under navbar:.\n\nExample:\nwebsite:\n  navbar:\n    left:\n      - href: index.qmd\n        text: Home\n      - href: projects.qmd\n        text: Projects\n      - href: education.qmd\n        text: Education\n      - href: resume.qmd\n        text: Resume\n\n\n\n\n\nTo deploy the portfolio:\n\nRender the site locally:\n\nquarto render\n\nPush changes to GitHub.\nEnable GitHub Pages:\n\nBranch: gh-pages (if using quarto publish gh-pages)\nOr use /docs folder if manually setting output-dir: docs in _quarto.yml.\n\nYour live website will be at:\n\nhttps://your-username.github.io/your-repo-name/\n\n\n\n\n\n\n\n\n\n\n\nTask\nReminder\n\n\n\n\nAdding new project\nCreate new .qmd inside posts/\n\n\nAdding new degree/certificate\nAdd new block inside education.qmd\n\n\nAdding experience\nCreate or update about.qmd\n\n\nUpdating styles\nModify styles.css\n\n\nUpdating site settings\nModify _quarto.yml\n\n\nDeploy new changes\nquarto render + Push to GitHub"
  },
  {
    "objectID": "readme.html#project-structure",
    "href": "readme.html#project-structure",
    "title": "Dhruv Garg — Portfolio Website",
    "section": "",
    "text": "├── index.qmd           # Homepage\n├── about.qmd           # About Me page\n├── projects.qmd        # Listing page for all projects \n├── resume.qmd          # Resume page \n├── education.qmd       # Education and certifications \n├── posts/              # Folder containing individual project pages\n│    ├── project1.qmd\n│    ├── project2.qmd\n│    └── ...\n├── images/             # Images (logos, project screenshots, gifs)\n├── styles.css          # Custom CSS for layout and design\n├── _quarto.yml         # Quarto site configuration\n└── README.md           # This file"
  },
  {
    "objectID": "readme.html#how-to-edit-or-add-content",
    "href": "readme.html#how-to-edit-or-add-content",
    "title": "Dhruv Garg — Portfolio Website",
    "section": "",
    "text": "The homepage contains cards for:\n\nProjects\nEducation\nExperience\n\nImportant: The “View Education” button links to education.qmd.\n\n\nTo add/change cards on the homepage, edit the &lt;div class=\"portfolio-card\"&gt; blocks inside index.qmd.\n\n\n\n\n\n\nprojects.qmd lists projects automatically if you use the listing: feature.\nEach project has a file inside the posts/ folder.\nExample project file: posts/retailpulse.qmd\n\n\nTo add a new project, create a new .qmd inside posts/ and Quarto will pick it up.\n\n\n\n\n\n\neducation.qmd uses a stacked layout — degrees first, certificates after.\nTo add a new degree or certificate:\n\nCopy an &lt;div class=\"education-item\"&gt; block.\nUpdate the title, organization, year, and description.\n(Optional) Add/update logos in images/.\n\n\n\n\n\n\n\nLinked to experience.qmd.\n\n\n\n\n\n\nMain styling such as:\n\nCard layout\nSection headings\nButton hover effects\nFonts and responsiveness\n\nEdit styles.css to customize the look of cards, sections, or entire site theme.\n\n\n\n\n\n\nControls the navbar links, site title, theme, and external assets.\nIf you add a new major page like education.qmd or experience.qmd, consider adding it to _quarto.yml under navbar:.\n\nExample:\nwebsite:\n  navbar:\n    left:\n      - href: index.qmd\n        text: Home\n      - href: projects.qmd\n        text: Projects\n      - href: education.qmd\n        text: Education\n      - href: resume.qmd\n        text: Resume"
  },
  {
    "objectID": "readme.html#deployment-github-pages",
    "href": "readme.html#deployment-github-pages",
    "title": "Dhruv Garg — Portfolio Website",
    "section": "",
    "text": "To deploy the portfolio:\n\nRender the site locally:\n\nquarto render\n\nPush changes to GitHub.\nEnable GitHub Pages:\n\nBranch: gh-pages (if using quarto publish gh-pages)\nOr use /docs folder if manually setting output-dir: docs in _quarto.yml.\n\nYour live website will be at:\n\nhttps://your-username.github.io/your-repo-name/"
  },
  {
    "objectID": "readme.html#quick-future-checklist",
    "href": "readme.html#quick-future-checklist",
    "title": "Dhruv Garg — Portfolio Website",
    "section": "",
    "text": "Task\nReminder\n\n\n\n\nAdding new project\nCreate new .qmd inside posts/\n\n\nAdding new degree/certificate\nAdd new block inside education.qmd\n\n\nAdding experience\nCreate or update about.qmd\n\n\nUpdating styles\nModify styles.css\n\n\nUpdating site settings\nModify _quarto.yml\n\n\nDeploy new changes\nquarto render + Push to GitHub"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\nDhruv Garg\n",
    "section": "",
    "text": "Dhruv Garg\n\n\nData Scientist  |  MDS @ UBC\n\n\n4 years of real-world impact with ML & data engineering\n\n\n\n\n\nExplore My Portfolio\n\n\n\n\n\n\nProjects\n\n\nWhere I turned theory into results.\n\nView Projects\n\n\n\n\n\nEducation\n\n\nDegrees and certifications that built my foundation.\n\nView Education\n\n\n\n\n\nExperience\n\n\nWhy you should hire me?\n\nView Experience\n\n\n\n\n\n LinkedIn  GitHub  Email"
  },
  {
    "objectID": "posts/seoul_bike_predictor/index.html",
    "href": "posts/seoul_bike_predictor/index.html",
    "title": "Seoul Bike Share Predictor",
    "section": "",
    "text": "In this project, we aimed to build a Docker image from scratch and create a fully reproducible analysis pipeline for future use.\nThe primary goal was to learn and practice key software engineering tools, including:\n\nSetting up Docker images\nImplementing a CI/CD pipeline\nManaging environments using Conda\nUsing make commands for workflow automation\nDocumenting the project using Quarto\n\nWe chose a simple dataset for this project, as the main focus was on understanding software tools rather than complex data modeling.\n\n\n\nRental bikes enhance urban mobility, but predicting their demand is crucial to maintaining a stable supply.\nThis project uses historical bike rental counts, weather information, and holiday data to forecast hourly bike demand in Seoul.\nThe dataset was sourced from the UCI Machine Learning Repository and described in studies by Sathishkumar V E, Jangwoo Park, and Yongyun Cho."
  },
  {
    "objectID": "posts/seoul_bike_predictor/index.html#about-the-project",
    "href": "posts/seoul_bike_predictor/index.html#about-the-project",
    "title": "Seoul Bike Share Predictor",
    "section": "",
    "text": "In this project, we aimed to build a Docker image from scratch and create a fully reproducible analysis pipeline for future use.\nThe primary goal was to learn and practice key software engineering tools, including:\n\nSetting up Docker images\nImplementing a CI/CD pipeline\nManaging environments using Conda\nUsing make commands for workflow automation\nDocumenting the project using Quarto\n\nWe chose a simple dataset for this project, as the main focus was on understanding software tools rather than complex data modeling.\n\n\n\nRental bikes enhance urban mobility, but predicting their demand is crucial to maintaining a stable supply.\nThis project uses historical bike rental counts, weather information, and holiday data to forecast hourly bike demand in Seoul.\nThe dataset was sourced from the UCI Machine Learning Repository and described in studies by Sathishkumar V E, Jangwoo Park, and Yongyun Cho."
  },
  {
    "objectID": "posts/seoul_bike_predictor/index.html#project-features",
    "href": "posts/seoul_bike_predictor/index.html#project-features",
    "title": "Seoul Bike Share Predictor",
    "section": "📈 Project Features",
    "text": "📈 Project Features\n\n🔍 Predicts hourly rental demand based on weather and calendar variables\n📦 Fully Dockerized environment for reproducible analysis\n🛠 Automated workflows using Makefile commands\n📊 Comprehensive EDA, model fitting, and evaluation\n📝 Detailed project documentation created using Quarto"
  },
  {
    "objectID": "posts/seoul_bike_predictor/index.html#learn-more",
    "href": "posts/seoul_bike_predictor/index.html#learn-more",
    "title": "Seoul Bike Share Predictor",
    "section": "📚 Learn More",
    "text": "📚 Learn More\nYou can find more information about the project in the GitHub repository.\nPlease refer to the README file in the repository for detailed setup instructions and project usage guidelines."
  },
  {
    "objectID": "posts/lecture_finder/index.html#lecture-rag-assistant",
    "href": "posts/lecture_finder/index.html#lecture-rag-assistant",
    "title": "Lecture RAG Assistant: Conversational Q&A Over Lecture Notes",
    "section": "📚 Lecture RAG Assistant",
    "text": "📚 Lecture RAG Assistant\nLecture RAG Assistant is a Retrieval-Augmented Generation (RAG) pipeline for querying lecture notes in .ipynb and .pdf format using a conversational interface powered by LLMs.\nIt combines the power of LangChain, ChromaDB, HuggingFace Embeddings, and OpenAI models (or local models) to generate accurate, source-grounded answers from your personal lecture material."
  },
  {
    "objectID": "posts/lecture_finder/index.html#project-structure",
    "href": "posts/lecture_finder/index.html#project-structure",
    "title": "Lecture RAG Assistant: Conversational Q&A Over Lecture Notes",
    "section": "Project Structure",
    "text": "Project Structure\nlecture_rag/\n├── app.py               # Streamlit dashboard for Q&A\n├── ingest.py            # Extracts & chunks lecture files, saves to ChromaDB\n├── qa_pipeline.py       # Loads retriever + LLM to create QA chain\n├── lectures/            # Directory with lecture PDFs/Notebooks\n├── chroma_langchain_db/ # Persisted vector DB (auto-created)\n├── README.md            # Project documentation"
  },
  {
    "objectID": "posts/lecture_finder/index.html#setup-instructions",
    "href": "posts/lecture_finder/index.html#setup-instructions",
    "title": "Lecture RAG Assistant: Conversational Q&A Over Lecture Notes",
    "section": "Setup Instructions",
    "text": "Setup Instructions\n\n1. Install Dependencies\npip install -r requirements.txt\nOr install manually:\npip install langchain openai chromadb streamlit sentence-transformers PyMuPDF\n\n\n2. Ingest Lecture Notes\nPut .pdf and/or .ipynb files in the ./lectures/ folder and run:\npython ingest.py\nThis will:\n\nRecursively scan the lecture folder\nChunk the content intelligently\nEmbed chunks with SentenceTransformers\nSave the vector DB in ChromaDB\n\n\n\n3. Launch the Q&A Dashboard\nstreamlit run app.py\nUse the web app to:\n\nAsk questions about your lecture content\nSee grounded responses with source highlighting"
  },
  {
    "objectID": "posts/lecture_finder/index.html#api-key-setup",
    "href": "posts/lecture_finder/index.html#api-key-setup",
    "title": "Lecture RAG Assistant: Conversational Q&A Over Lecture Notes",
    "section": "🔑 API Key Setup",
    "text": "🔑 API Key Setup\nTo use OpenAI models like gpt-3.5-turbo, set:\nexport OPENAI_API_KEY=\"your_openai_key_here\"\nIf no key is found, the app skips LLM inference gracefully."
  },
  {
    "objectID": "posts/lecture_finder/index.html#how-it-works",
    "href": "posts/lecture_finder/index.html#how-it-works",
    "title": "Lecture RAG Assistant: Conversational Q&A Over Lecture Notes",
    "section": "🧐 How It Works",
    "text": "🧐 How It Works\n\nIngestion (ingest.py)\n\nLoads .ipynb via NotebookLoader, .pdf via PyPDFLoader\nSplits text with RecursiveCharacterTextSplitter\nEmbeds using all-mpnet-base-v2\nStores in a persistent ChromaDB vector store\n\n\n\nRetrieval (qa_pipeline.py)\n\nLoads the vector DB as retriever\nWraps LLM and retriever with RetrievalQA from LangChain\n\n\n\nInteraction (app.py)\n\nAccepts user question\nFetches relevant chunks\nConstructs answer and shows references"
  },
  {
    "objectID": "posts/lecture_finder/index.html#optional-features-todo",
    "href": "posts/lecture_finder/index.html#optional-features-todo",
    "title": "Lecture RAG Assistant: Conversational Q&A Over Lecture Notes",
    "section": "🚀 Optional Features (TODO)",
    "text": "🚀 Optional Features (TODO)\n\nSupport for .md or .html files\nUpload feature in Streamlit\nUse local LLMs (e.g., Mistral, Llama.cpp)\nRerank retrieved chunks for better answers"
  },
  {
    "objectID": "posts/lecture_finder/index.html#credits",
    "href": "posts/lecture_finder/index.html#credits",
    "title": "Lecture RAG Assistant: Conversational Q&A Over Lecture Notes",
    "section": "🙌 Credits",
    "text": "🙌 Credits\n\nBuilt with LangChain\nEmbeddings via SentenceTransformers\nPDF parsing by PyMuPDF\nInterface via Streamlit"
  },
  {
    "objectID": "posts/lecture_finder/index.html#example-questions",
    "href": "posts/lecture_finder/index.html#example-questions",
    "title": "Lecture RAG Assistant: Conversational Q&A Over Lecture Notes",
    "section": "💬 Example Questions",
    "text": "💬 Example Questions\n\n“What is a confounding variable?”\n“How does backpropagation work?”\n“What are the assumptions of linear regression?”"
  },
  {
    "objectID": "posts/lecture_finder/index.html#learn-more",
    "href": "posts/lecture_finder/index.html#learn-more",
    "title": "Lecture RAG Assistant: Conversational Q&A Over Lecture Notes",
    "section": "🔗 Learn More",
    "text": "🔗 Learn More\nVisit the GitHub repository for full setup, contribution guide, and demo walkthroughs."
  },
  {
    "objectID": "posts/vancouver_crime/index.html",
    "href": "posts/vancouver_crime/index.html",
    "title": "Vancouver Crime Statistics Dashboard",
    "section": "",
    "text": "For this project, I wanted to build a Shiny application from scratch.\nI downloaded PDF reports from the Vancouver Police Department (VPD) portal and used a PDF extraction library to retrieve the crime data.\nThe extracted data was then processed and used to create this interactive dashboard.\nThis project helped me learn the basics of Shiny app development and gave me hands-on experience working with real-world data sources.\n\n\n\nCrime statistics provide valuable insights into public safety and law enforcement effectiveness.\nThis dashboard is designed for policymakers, researchers, and local authorities to analyze crime trends across Vancouver neighborhoods.\nUsing the dashboard, users can:\n\nTrack crime trends over time\n\nCompare crime types across neighborhoods\n\nAnalyze monthly crime patterns\n\nFilter and explore data by date, location, and type"
  },
  {
    "objectID": "posts/vancouver_crime/index.html#motivation",
    "href": "posts/vancouver_crime/index.html#motivation",
    "title": "Vancouver Crime Statistics Dashboard",
    "section": "",
    "text": "For this project, I wanted to build a Shiny application from scratch.\nI downloaded PDF reports from the Vancouver Police Department (VPD) portal and used a PDF extraction library to retrieve the crime data.\nThe extracted data was then processed and used to create this interactive dashboard.\nThis project helped me learn the basics of Shiny app development and gave me hands-on experience working with real-world data sources.\n\n\n\nCrime statistics provide valuable insights into public safety and law enforcement effectiveness.\nThis dashboard is designed for policymakers, researchers, and local authorities to analyze crime trends across Vancouver neighborhoods.\nUsing the dashboard, users can:\n\nTrack crime trends over time\n\nCompare crime types across neighborhoods\n\nAnalyze monthly crime patterns\n\nFilter and explore data by date, location, and type"
  },
  {
    "objectID": "posts/vancouver_crime/index.html#app-overview",
    "href": "posts/vancouver_crime/index.html#app-overview",
    "title": "Vancouver Crime Statistics Dashboard",
    "section": "🖥️ App Overview",
    "text": "🖥️ App Overview\nBuilt with Shiny in R, this dashboard offers an interactive platform for exploring Vancouver crime data.\n\nKey Features\n\nNeighborhood Selection – choose one or multiple neighborhoods\n\nCrime Type Filtering – focus on specific crime categories\n\nDate Range Selection – filter data by time period\n\nDynamic Plot Selection – switch between line and bar charts\n\nHeatmap Visualization – view monthly crime distributions\n\nInteractive Data Table – browse and search detailed records"
  },
  {
    "objectID": "posts/vancouver_crime/index.html#learn-more",
    "href": "posts/vancouver_crime/index.html#learn-more",
    "title": "Vancouver Crime Statistics Dashboard",
    "section": "📚 Learn More",
    "text": "📚 Learn More\nYou can find more details about the project in the GitHub repository.\nPlease refer to the README file for setup instructions, usage examples, and additional project documentation."
  },
  {
    "objectID": "posts/num-theory/index.html#about-the-package",
    "href": "posts/num-theory/index.html#about-the-package",
    "title": "Number Theory Utilities for Project Euler",
    "section": "📦 About the Package",
    "text": "📦 About the Package\nnum_theory is a high-performance Python package designed to simplify solving number theory problems — especially those from Project Euler.\nThe primary goal of this project was to gain practical experience in creating and publishing an open-source Python package by following industry best practices."
  },
  {
    "objectID": "posts/num-theory/index.html#project-features",
    "href": "posts/num-theory/index.html#project-features",
    "title": "Number Theory Utilities for Project Euler",
    "section": "📈 Project Features",
    "text": "📈 Project Features\nDuring the development of this package, we learned how to:\n\nManage dependencies using Poetry\nWrite and run unit tests\nSet up a CI/CD pipeline to automatically publish to PyPI\nIntegrate code coverage reporting with Codecov\nStructure projects using Cookiecutter templates\nHost project documentation on ReadTheDocs\n\nThe package includes functionalities such as:\n\nFast prime number generation\nPrimality testing\nPrime factorization\nArithmetic progression calculations\nA clean and intuitive API for easy use"
  },
  {
    "objectID": "posts/num-theory/index.html#learn-more",
    "href": "posts/num-theory/index.html#learn-more",
    "title": "Number Theory Utilities for Project Euler",
    "section": "📚 Learn More",
    "text": "📚 Learn More\nYou can find more information about the project in the GitHub repository.\nPlease refer to the README file for detailed setup instructions, usage examples, and contribution guidelines."
  },
  {
    "objectID": "posts/retail_pulse/index.html",
    "href": "posts/retail_pulse/index.html",
    "title": "RetailPulse: Online Retail Analytics Dashboard",
    "section": "",
    "text": "This project was primarily focused on learning how to use Dash to build interactive dashboards.\nWe also explored how to integrate Altair visualizations within Dash applications.\n\n\n\nRetail operations managers often face challenges in managing inventory, tracking sales trends, and identifying market expansion opportunities.\nMaking informed, data-driven decisions quickly is crucial for maintaining a competitive edge.\nRetailPulse was developed to address this need by providing an interactive dashboard that gives retailers real-time insights into their business performance."
  },
  {
    "objectID": "posts/retail_pulse/index.html#motivation-and-purpose",
    "href": "posts/retail_pulse/index.html#motivation-and-purpose",
    "title": "RetailPulse: Online Retail Analytics Dashboard",
    "section": "",
    "text": "This project was primarily focused on learning how to use Dash to build interactive dashboards.\nWe also explored how to integrate Altair visualizations within Dash applications.\n\n\n\nRetail operations managers often face challenges in managing inventory, tracking sales trends, and identifying market expansion opportunities.\nMaking informed, data-driven decisions quickly is crucial for maintaining a competitive edge.\nRetailPulse was developed to address this need by providing an interactive dashboard that gives retailers real-time insights into their business performance."
  },
  {
    "objectID": "posts/retail_pulse/index.html#data-attribution",
    "href": "posts/retail_pulse/index.html#data-attribution",
    "title": "RetailPulse: Online Retail Analytics Dashboard",
    "section": "📂 Data Attribution",
    "text": "📂 Data Attribution\nThis project uses data from the Online Retail Dataset, available through the UC Irvine Machine Learning Repository."
  },
  {
    "objectID": "posts/retail_pulse/index.html#features",
    "href": "posts/retail_pulse/index.html#features",
    "title": "RetailPulse: Online Retail Analytics Dashboard",
    "section": "🚀 Features",
    "text": "🚀 Features\n\nMonitor sales trends over time with interactive line charts\n\nAnalyze customer retention and repeat purchasing behavior\n\nExplore regional sales distribution with geographic maps\n\nEvaluate product performance using bar charts and word clouds\n\n\n\n\nRetailPulse Demo"
  },
  {
    "objectID": "posts/retail_pulse/index.html#learn-more",
    "href": "posts/retail_pulse/index.html#learn-more",
    "title": "RetailPulse: Online Retail Analytics Dashboard",
    "section": "📚 Learn More",
    "text": "📚 Learn More\nYou can find more details about the project in the GitHub repository.\nPlease refer to the README file for setup instructions, usage examples, and additional project documentation."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Lecture RAG Assistant: Conversational Q&A Over Lecture Notes\n\n\n\n\n\n\nPython\n\n\nRAG\n\n\nLLM\n\n\nLangChain\n\n\nLecture Notes\n\n\nStreamlit\n\n\n\nA Retrieval-Augmented Generation (RAG) app for querying lecture notes via LangChain, ChromaDB, and LLMs like OpenAI.\n\n\n\n\n\nJul 30, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nRetailPulse: Online Retail Analytics Dashboard\n\n\n\n\n\n\nDash\n\n\nVisualization\n\n\nRetail\n\n\nPython\n\n\n\nAn interactive dashboard for real-time retail insights — built with Dash, Altair, and Pandas.\n\n\n\n\n\nMar 17, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nVancouver Crime Statistics Dashboard\n\n\n\n\n\n\nR\n\n\nShiny\n\n\nData Visualization\n\n\nCrime\n\n\n\nAn interactive Shiny dashboard to explore neighborhood-wise crime patterns in Vancouver using time-series, heatmaps, and filters.\n\n\n\n\n\nFeb 28, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nNumber Theory Utilities for Project Euler\n\n\n\n\n\n\nPython\n\n\nPackage\n\n\nProject Euler\n\n\nNumber Theory\n\n\n\nA Python package developed to practice open-source publishing workflows, automation, and best practices for user-friendly libraries.\n\n\n\n\n\nFeb 3, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nSeoul Bike Share Predictor\n\n\n\n\n\n\nPython\n\n\nMachine Learning\n\n\nForecasting\n\n\nDocker\n\n\n\nPredicting hourly rental bike demand in Seoul using weather and holiday data. Built with Dockerized JupyterLab pipelines and automated workflows.\n\n\n\n\n\nDec 16, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "experience.html",
    "href": "experience.html",
    "title": "Professional Experience",
    "section": "",
    "text": "💼 Work Experience\n\n\n\n\nTeaching Assistant\n\n\nUniversity of British Columbia | June 2025 – July 2025Vancouver, Canada\n\n\n\nSupported Professional MBA students in mastering Python programming concepts, including data visualization using Matplotlib. Clarified course material, and provided guidance on assignments and best practices in coding for analytics.\n\n\n\n\n\n\n\n\n\n\nGraduate Academic Assistant\n\n\nUniversity of British Columbia | Dec 2024 – Mar 2025Vancouver, Canada\n\n\n\nEvaluated 4–8 applications per week for the MDS program, assessing candidates’ suitability.\n\n\n\n\n\n\n\n\n\n\nData Scientist\n\n\nHighbrow Technology Inc Limited | Apr 2024 – Aug 2024Remote – NC, USA\n\n\n\nImplemented systematic evaluation frameworks to assess LLM outputs across multiple dimensions including accuracy, coherence, and task completion.\n\n\nAnalyzed and quality-assured 100+ Python scripts weekly, ensuring code quality and maintaining evaluation standards for LLM testing.\n\n\n\n\n\n\n\n\n\n\nData Scientist\n\n\nSprigHub | Mar 2021 – Apr 2024Remote – CA, USA\n\n\n\nCo-developed a serverless forecasting model using Python, SQL, and AWS Lambda, helping clients accurately forecast revenue and make informed decisions.\n\n\nDesigned a statistical marketing attribution model that improved ROI by 5–7% through better platform-level conversion tracking.\n\n\nOptimized attribution workflows with PySpark and SQL, cutting job costs by 70% while handling 10+ million records from GA4.\n\n\nBuilt an ML-based attribution model using AWS SageMaker, XGBoost, and clustering techniques to enhance model accuracy.\n\n\nCreated scalable ETL pipelines in Python and PySpark to transfer data from Google Cloud to AWS, enabling seamless data integration.\n\n\nDelivered automated insights with Python, Pandas, and Scikit-learn — improving data analysis efficiency by 30%.\n\n\nCollaborated with UI and DevOps teams to ensure smooth feature rollouts, and built dashboards for client-facing performance tracking."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I’m Dhruv Garg, a Data Scientist with 3 years of hands-on industry experience and currently pursuing my Master of Data Science at the University of British Columbia. I specialize in designing and deploying machine learning solutions that deliver measurable business value — particularly in marketing analytics and performance optimization.\nPreviously, I’ve worked with startups and IT consultancies across North America, leading initiatives in large-scale data processing, LLM evaluation, marketing attribution modeling, and cloud-based ETL pipelines. My work has led to improved ROI, reduced infrastructure costs, and streamlined analytics workflows.\nIn addition to professional roles, I’ve developed open-source packages and interactive dashboards as part of my academic projects, using tools like Dash, Docker, Quarto, and PySpark.\nI’m passionate about building intelligent systems that are both scalable and human-centered — and always open to collaborating on impactful data projects."
  }
]